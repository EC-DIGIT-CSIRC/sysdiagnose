import unittest
import os
import glob
from sysdiagnose import Sysdiagnose


class SysdiagnoseTestCase(unittest.TestCase):

    required_fields_jsonl = ['message', 'datetime', 'timestamp_desc', 'module']

    @classmethod
    def setUpClass(cls):
        # theoretically better to use tempfile.TemporaryDirectory(), but that would prevent re-use between test runs
        # differently better, and reused over multiple test runs
        # if we'd autogenerated tempdirs we'd also have to figure out a system to pass on the name to the instantiated classes. (singleton?)
        cls.tmp_folder = os.path.join('tests', 'tmp')
        os.makedirs(cls.tmp_folder, exist_ok=True)

        cases_path = os.path.join(cls.tmp_folder, 'cases')
        cls.sd = Sysdiagnose(cases_path=cases_path)

        # if cases.json does not exist, create cases from testdata,
        # otherwise assume cases are already created and extracted
        if os.path.exists(os.path.join(cases_path, 'cases.json')):
            print("Cases already exist, skipping creation")
        else:
            # find all folders such as
            # - testdata/iOSxx/sysdiagnose_YYYY.MM.DD_HH-MM-SS-SSSS_....tar.gz
            # - testdata-private/iOSxx/sysdiagnose_YYYY.MM.DD_HH-MM-SS-SSSS_....tar.gz
            # this allows testing locally with more data, while keeping online tests coherent
            sd_archive_files = [name for name in glob.glob('tests/testdata*/**/*.tar.gz', recursive=True)]
            for archive_file in sd_archive_files:
                print(f"Creating case from {archive_file}")
                try:
                    cls.sd.create_case(archive_file)
                except ValueError as ve:
                    # ignore errors as we know we may have multiple times the same case
                    print(f"Warning: {ve}")

    def setUp(self):
        self.tmp_folder = os.path.join('tests', 'tmp')
        cases_path = os.path.join(self.tmp_folder, 'cases')
        self.sd = Sysdiagnose(cases_path=cases_path)

    def get_parsers(self):
        """
        List all parsers in the parsers folder.
        We can't use the self.sd.get_parsers() method as that would discard broken parsers.
        """
        results = []
        modules = glob.glob(os.path.join(self.sd.config.parsers_folder, "*.py"))
        for item in modules:
            if item.endswith('__init__.py'):
                continue
            results.append(os.path.splitext(os.path.basename(item))[0])

        results.sort()
        return results

    def get_analysers(self):
        """
        List all analysers in the analysers folder.
        We can't use the self.sd.get_analysers() method as that would discard broken analysers.
        """
        results = []
        modules = glob.glob(os.path.join(self.sd.config.analysers_folder, "*.py"))
        for item in modules:
            if item.endswith('__init__.py'):
                continue
            results.append(os.path.splitext(os.path.basename(item))[0])

        results.sort()
        return results

    def assert_has_required_fields_jsonl(self, entry: dict):
        """
        Check if the entry has all required fields.
        """
        for field in self.required_fields_jsonl:
            self.assertTrue(field in entry, f'Parser result entry did not contain a {field}.')
